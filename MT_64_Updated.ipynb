{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MT Data-conditioned VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CVAE/VAE code trained on Line 1 Central Region, with Line 3 as validation and Line 2 as test 1 (eventually - next step is to get test set(s) finalized and included in code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import scipy as sp\n",
    "from scipy import interpolate\n",
    "# import scipy.interpolate\n",
    "\n",
    "from cgnn import cvae_mt64_updated as vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "run = 's4'\n",
    "if not os.path.exists(run):\n",
    "    os.makedirs(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def import_file(file):\n",
    "    with open(file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = list(reader)\n",
    "    line = np.array(data, dtype=float)\n",
    "    cond = line[:,25:55]\n",
    "    # obs_xs = line[:,270:285]\n",
    "    # print(obs_xs.shape)\n",
    "    obs_zs = -line[:,286:301]\n",
    "    print(obs_zs.shape)\n",
    "    print(cond.shape)\n",
    "    # obs_total = np.concatenate((obs_xs, obs_zs), axis=1)\n",
    "    # print(obs_total.shape)\n",
    "    pred_zs = line[:,348:363]\n",
    "    return line,cond, obs_zs, pred_zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "line1,cond1, obs1, pred1 = import_file('Line1_Central-Copy1.csv')\n",
    "line2,cond2, obs2, pred2 = import_file('Line2_Central-Copy1.csv')\n",
    "line3,cond3, obs3, pred3 = import_file('Line3_Central-Copy1.csv')\n",
    "\n",
    "\n",
    "\n",
    "# print(obs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "line94, cond94, obs94, pred94 = import_file('Central_Line94.csv')\n",
    "\n",
    "line15, cond15, obs15, pred15 = import_file('Central_Line15.csv')\n",
    "line30, cond30, obs30, pred30 = import_file('Central_Line30.csv')\n",
    "line45, cond45, obs45, pred45 = import_file('Central_Line45.csv')\n",
    "line60, cond60, obs60, pred60 = import_file('Central_Line60.csv')\n",
    "line75, cond75, obs75, pred75 = import_file('Central_Line75.csv')\n",
    "print(cond15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# np.save('Line94_Central.npy', line94)\n",
    "# np.save('Line94_Central_Conductivity.npy',cond94)\n",
    "# np.save('Line94_Central_Observations.npy',obs94)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "print(len(cond1[:,0]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "np.save('Line1_Central.npy', line1)\n",
    "# np.save('Line1_Central_Conductivity.npy',cond1)\n",
    "np.save('Line1_Central_Observations.npy',obs1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "np.save('Line2_Central.npy', line2)\n",
    "# np.save('Line2_Central_Conductivity.npy',cond2)\n",
    "np.save('Line2_Central_Observations.npy',obs2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "np.save('Line3_Central.npy', line3)\n",
    "# np.save('Line3_Central_Conductivity.npy',cond3)\n",
    "np.save('Line3_Central_Observations.npy',obs3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "data1 = np.load('Line1_Central.npy')\n",
    "np.load('Line1_Central_Observations.npy')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "data2 = np.load('Line2_Central.npy')\n",
    "np.load('Line2_Central_Conductivity.npy')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "data3 = np.load('Line3_Central.npy')\n",
    "np.load('Line3_Central_Conductivity.npy')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "print(len(cond1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# remote reference frequencies\n",
    "#   7.680002e+02   5.120000e+02   3.840000e+02   2.560000e+02   1.920000e+02   1.280000e+02\n",
    "#   9.599997e+01   6.400000e+01   4.800001e+01   3.200000e+01   2.400000e+01   1.600000e+01\n",
    "#   1.200000e+01   8.000000e+00   5.999999e+00   4.000000e+00   3.000000e+00   2.000000e+00\n",
    "#   1.500000e+00   1.000000e+00   7.500002e-01   5.000000e-01   3.750000e-01   2.500000e-01\n",
    "#   1.875000e-01\n",
    "\n",
    "\n",
    "# mesh\n",
    "# 64 ft\n",
    "cell_size = 32*0.3048\n",
    "depth_to_top = 32*0.3048\n",
    "n_cells = 32\n",
    "# one fewer depth; last cell extends to inf\n",
    "#depths = depth_to_top + np.arange(1,n_cells)*cell_size\n",
    "#depths to bottom\n",
    "depths0 = np.array([4,8.4,13.24,18.56,24.42,30.86,37.95,45.74,54.31,63.74,74.11,85.52,98.07,111.88,127.07,143.78,162.16,182.38,204.62,229.08,255.99,285.59,318.15,353.97,393.37,436.71,484.38,536.82,594.5])\n",
    "n_depths = len(depths0)\n",
    "print(n_depths)\n",
    "# data frequencies\n",
    "# conservative, lines up with remote referenced stations, minus one frequency to avoid extrapolation\n",
    "f_a = np.logspace(-2, 9, num=12, base=2)\n",
    "f_b = np.logspace(-4, 7, num=12, base=2)*3\n",
    "time0 = np.array([0.013,0.039,0.065,0.104,0.169,0.273,0.443,0.703,1.094,1.693,2.63,4.102,6.406,9.961,16.055])*1e-3\n",
    "# frequencies = np.logspace(-4, 10, 15, base=2)\n",
    "nt = len(time0)\n",
    "print(nt)\n",
    "# data are only real\n",
    "ndata = nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "depth = np.append(0,depths0)\n",
    "\n",
    "def format_models(file, depths):\n",
    "    cond_new = np.zeros((len(file[:,0]),32))\n",
    "    for i in range(len(file[:,0])):\n",
    "        x = file[i]\n",
    "        y = depths\n",
    "        f = sp.interpolate.interp1d(y,x)\n",
    "        y_new = [554,573]\n",
    "        x_new = f(y_new)\n",
    "        cond_new[i] = np.append(x,x_new)\n",
    "    return cond_new\n",
    "\n",
    "cond94_new = format_models(cond94,depth)\n",
    "\n",
    "print(cond94_new.shape)\n",
    "print(len(depth))  \n",
    "# print(len(cond1_new[0]))\n",
    "# print(cond1_new[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def format_raw(file,times):\n",
    "    obs_new = np.zeros((len(file[:,0]),16))\n",
    "    for i in range(len(file[:,0])):\n",
    "        x = file[i]\n",
    "        y = times\n",
    "        f = sp.interpolate.interp1d(y,x)\n",
    "        y_new = [16.054*1e-3]\n",
    "        x_new = f(y_new)\n",
    "        obs_new[i] = np.append(x,x_new)\n",
    "    return obs_new\n",
    "    \n",
    "obs94_new = format_raw(obs94,time0)\n",
    "\n",
    "print(obs94_new.shape)\n",
    "print(len(time0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# for i in range(0,1000,10):\n",
    "#     print(np.mean(cond1[i]-cond1[0]))\n",
    "#     # plt.plot(cond1[0],depth)\n",
    "#     # plt.plot(cond1[i],depth)\n",
    "#     # plt.gca().invert_yaxis()\n",
    "def compute_moving_average(models, window_size=5):\n",
    "    \"\"\"\n",
    "    Apply moving average to each model (row) in the dataset.\n",
    "    \"\"\"\n",
    "    return np.array([\n",
    "        np.convolve(model, np.ones(window_size)/window_size, mode='same')\n",
    "        for model in models\n",
    "    ])\n",
    "\n",
    "def select_diverse_models(models, threshold=0.01, metric='mse', window_size=5):\n",
    "    \"\"\"\n",
    "    Select a diverse subset of models based on moving average smoothed values.\n",
    "\n",
    "    Parameters:\n",
    "    - models: np.ndarray of shape (N, 30)\n",
    "    - threshold: float, minimum difference to count as diverse\n",
    "    - metric: str, 'mse' or 'cosine'\n",
    "    - window_size: int, size of the moving average window\n",
    "\n",
    "    Returns:\n",
    "    - indices: np.ndarray of selected row indices\n",
    "    \"\"\"\n",
    "    smoothed = compute_moving_average(models, window_size)\n",
    "    selected = [0]  # Always include the first model\n",
    "\n",
    "    for i in range(1, len(smoothed)):\n",
    "        prev_model = smoothed[selected[-1]]\n",
    "        curr_model = smoothed[i]\n",
    "\n",
    "        if metric == 'mse':\n",
    "            diff = np.mean((curr_model - prev_model)**2)\n",
    "        elif metric == 'cosine':\n",
    "            diff = cosine(curr_model, prev_model)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported metric. Use 'mse' or 'cosine'.\")\n",
    "\n",
    "        if diff > threshold:\n",
    "            selected.append(i)\n",
    "\n",
    "    return np.array(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(cond1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Select diverse subset\n",
    "diverse_indices1 = select_diverse_models(cond1, threshold=0.01, metric='mse', window_size=3)\n",
    "\n",
    "# Extract selected models\n",
    "diverse_models1 = cond1[diverse_indices1]\n",
    "diverse_data1 = obs1[diverse_indices1]\n",
    "print(len(diverse_models1), len(diverse_data1))\n",
    "\n",
    "print(f\"Selected {len(diverse_indices1)} diverse models from {len(cond1)} total\")\n",
    "print(diverse_models1.shape)\n",
    "\n",
    "# Select diverse subset\n",
    "diverse_indices15 = select_diverse_models(cond15, threshold=0.01, metric='mse', window_size=3)\n",
    "\n",
    "# Extract selected models\n",
    "diverse_models15 = cond15[diverse_indices15]\n",
    "diverse_data15 = obs15[diverse_indices15]\n",
    "print(len(diverse_models15), len(diverse_data15))\n",
    "\n",
    "print(f\"Selected {len(diverse_indices15)} diverse models from {len(cond15)} total\")\n",
    "print(diverse_models15.shape)\n",
    "\n",
    "# Select diverse subset\n",
    "diverse_indices30 = select_diverse_models(cond30, threshold=0.01, metric='mse', window_size=3)\n",
    "\n",
    "# Extract selected models\n",
    "diverse_models30 = cond30[diverse_indices30]\n",
    "diverse_data30 = obs30[diverse_indices30]\n",
    "print(len(diverse_models30), len(diverse_data30))\n",
    "\n",
    "print(f\"Selected {len(diverse_indices30)} diverse models from {len(cond30)} total\")\n",
    "\n",
    "# Select diverse subset\n",
    "diverse_indices45 = select_diverse_models(cond45, threshold=0.01, metric='mse', window_size=3)\n",
    "\n",
    "# Extract selected models\n",
    "diverse_models45 = cond45[diverse_indices45]\n",
    "diverse_data45 = obs45[diverse_indices45]\n",
    "print(len(diverse_models45), len(diverse_data45))\n",
    "\n",
    "print(f\"Selected {len(diverse_indices45)} diverse models from {len(cond45)} total\")\n",
    "\n",
    "# Select diverse subset\n",
    "diverse_indices60 = select_diverse_models(cond60, threshold=0.01, metric='mse', window_size=3)\n",
    "\n",
    "# Extract selected models\n",
    "diverse_models60 = cond60[diverse_indices60]\n",
    "diverse_data60 = obs60[diverse_indices60]\n",
    "print(len(diverse_models60), len(diverse_data60))\n",
    "\n",
    "print(f\"Selected {len(diverse_indices60)} diverse models from {len(cond60)} total\")\n",
    "\n",
    "# Select diverse subset\n",
    "diverse_indices75 = select_diverse_models(cond75, threshold=0.01, metric='mse', window_size=3)\n",
    "\n",
    "# Extract selected models\n",
    "diverse_models75 = cond75[diverse_indices75]\n",
    "diverse_data75 = obs75[diverse_indices75]\n",
    "print(len(diverse_models75), len(diverse_data75))\n",
    "\n",
    "print(f\"Selected {len(diverse_indices75)} diverse models from {len(cond75)} total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cond1_sampled = format_models(diverse_models1,depth)\n",
    "obs1_sampled = format_raw(diverse_data1, time0)\n",
    "\n",
    "cond15_new = format_models(diverse_models15,depth)\n",
    "cond30_new = format_models(diverse_models30,depth)\n",
    "cond45_new = format_models(diverse_models45,depth)\n",
    "cond60_new = format_models(diverse_models60,depth)\n",
    "cond75_new = format_models(diverse_models75,depth)\n",
    "\n",
    "obs15_new = format_raw(diverse_data15,time0)\n",
    "obs30_new = format_raw(diverse_data30,time0)\n",
    "obs45_new = format_raw(diverse_data45,time0)\n",
    "obs60_new = format_raw(diverse_data60,time0)\n",
    "obs75_new = format_raw(diverse_data75,time0)\n",
    "\n",
    "print(cond1_sampled.shape)\n",
    "print(obs1_sampled.shape)\n",
    "print(cond75_new.shape)\n",
    "print(obs75_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cond_sampled = np.append(cond1_sampled,cond15_new,axis=0)\n",
    "cond_sampled = np.append(cond_sampled,cond30_new,axis=0)\n",
    "cond_sampled = np.append(cond_sampled,cond45_new,axis=0)\n",
    "cond_sampled = np.append(cond_sampled,cond60_new,axis=0)\n",
    "cond_sampled = np.append(cond_sampled,cond75_new,axis=0)\n",
    "\n",
    "obs_sampled = np.append(obs1_sampled, obs15_new, axis=0)\n",
    "obs_sampled = np.append(obs_sampled, obs30_new, axis=0)\n",
    "obs_sampled = np.append(obs_sampled, obs45_new, axis=0)\n",
    "obs_sampled = np.append(obs_sampled, obs60_new, axis=0)\n",
    "obs_sampled = np.append(obs_sampled, obs75_new, axis=0)\n",
    "\n",
    "print(cond_sampled.shape)\n",
    "print(obs_sampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- Step 1: Load sampling pattern ---\n",
    "# If your Excel file is actually saved as CSV, use this:\n",
    "pattern = np.loadtxt('1D_ergodic_100_50.csv', delimiter=',', dtype=int)\n",
    "\n",
    "# Flatten in case it’s multi-dimensional (e.g., 100×1 or 1×100)\n",
    "pattern = pattern.flatten()\n",
    "pattern_length = len(pattern)\n",
    "print(f\"Pattern length: {pattern_length}\")\n",
    "\n",
    "# --- Step 2: Load the large dataset (.npy file) ---\n",
    "# data = np.load('large_dataset.npy')\n",
    "model_length = len(cond_sampled)\n",
    "data_length = len(obs_sampled)\n",
    "\n",
    "print(f\"Model length: {model_length}, Data length: {data_length}\")\n",
    "\n",
    "# --- Step 3: Repeat pattern to cover the full dataset ---\n",
    "repeats = int(np.ceil(data_length / pattern_length))\n",
    "repeated_pattern = np.tile(pattern, repeats)[:data_length]\n",
    "\n",
    "# --- Step 4: Apply ergodic sampling mask ---\n",
    "sampled_models = cond_sampled[repeated_pattern == 1]\n",
    "sampled_data = obs_sampled[repeated_pattern == 1]\n",
    "\n",
    "# --- Step 5: Save or return sampled data ---\n",
    "# np.save('ergodic_sampled_output.npy', sampled_data)\n",
    "\n",
    "print(f\"Sampled {len(sampled_models)} and {len(sampled_data)} of {model_length} and {data_length} total points \"\n",
    "      f\"({len(sampled_models) / model_length:.1%}).\"\n",
    "      f\"({len(sampled_data) / data_length:.1%})\")\n",
    "\n",
    "print(sampled_models.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "np.save('Sampled_Conductivity.npy',sampled_models)\n",
    "np.save('Sampled_Observations.npy',sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "depths=np.append(depths0,[554,573])\n",
    "print(depths.shape)\n",
    "\n",
    "# np.save('Line94_Central_Conductivity.npy',cond94_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "times = np.append(time0,16.054*1e-3)\n",
    "times.sort()\n",
    "print(len(times))\n",
    "\n",
    "# np.save('Line94_Central_Observations.npy',obs94_new)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# np.save('Line1_Central_Conductivity.npy',cond1_new)\n",
    "# np.save('Line2_Central_Conductivity.npy',cond2_new)\n",
    "# np.save('Line3_Central_Conductivity.npy',cond3_new)\n",
    "\n",
    "np.save('Line1_Central_Observations.npy',obs1_new)\n",
    "np.save('Line2_Central_Observations.npy',obs2_new)\n",
    "np.save('Line3_Central_Observations.npy',obs3_new)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "print(cond1_new[0])\n",
    "print(obs1_new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# x = np.arange(depths.size)\n",
    "# new_length = 63\n",
    "# new_x = np.linspace(x.min(), x.max(), new_length)\n",
    "# new_depths = sp.interpolate.interp1d(x, depths)(new_x)\n",
    "# print(new_depths)\n",
    "# print(len(new_depths))\n",
    "# depths = new_depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training models and Create neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# normalize model parameters between -1 and 1\n",
    "# remember, min resistivity is 0.01, max is 1e5\n",
    "# Gaussian infill potentially allows for values outside this range, but not likely\n",
    "min_model = np.log(1e-5)\n",
    "max_model = np.log(1e5)\n",
    "# pad by norm_pad, so that a bunch of values don't end up at -1\n",
    "norm_pad = 0.1\n",
    "\n",
    "# create network\n",
    "network = vae.CVAE(depths,\n",
    "                   min_model=min_model,\n",
    "                   max_model=max_model,\n",
    "                   times = times,\n",
    "                   norm_pad=norm_pad,\n",
    "                   data_std=0.1,\n",
    "                   model_std=.01,\n",
    "                   beta_vae=4,\n",
    "                   model_loss_type='mae',\n",
    "                   data_loss_type='mae'\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Due to ranging orders of magnitude - recommended to keep\n",
    "def preprocess(filename):\n",
    "    '''\n",
    "    Read RILD values from npy file\n",
    "    Convert to log conductivity\n",
    "    Reshape to include channel dimension\n",
    "    '''\n",
    "    x = np.log(np.load(filename))\n",
    "    x = x.reshape(-1, n_cells, 1)\n",
    "    return x\n",
    "\n",
    "x_train_log = preprocess('Sampled_Conductivity.npy')\n",
    "print(x_train_log.shape)\n",
    "x_validate_log = preprocess('Line3_Central_Conductivity.npy')\n",
    "x_test_log = preprocess('Line2_Central_Conductivity.npy')\n",
    "x_test_log94 = preprocess('Line94_Central_Conductivity.npy')\n",
    "# x_test2_log = preprocess('KGS_RILD_64ft_test2.npy')\n",
    "# print(x_train_log)\n",
    "\n",
    "x_train_raw = np.load('Sampled_Observations.npy')\n",
    "x_validate_raw = np.load('Line3_Central_Observations.npy')\n",
    "x_test_raw = np.load('Line2_Central_Observations.npy')\n",
    "print(x_test_raw.shape)\n",
    "x_test_raw94 = np.load('Line94_Central_Observations.npy')\n",
    "print(x_test_raw94.shape)\n",
    "#print(x_train_raw_log)\n",
    "\n",
    "# x_train_raw = network.model_to_tanhs(x_train_raw_log)\n",
    "# x_validate_raw = network.model_to_tanhs(x_validate_raw_log)\n",
    "# x_test1_raw = network.model_to_tanhs(x_test1_raw_log)\n",
    "\n",
    "x_train = network.model_to_tanhs(x_train_log)\n",
    "x_validate = network.model_to_tanhs(x_validate_log)\n",
    "x_test = network.model_to_tanhs(x_test_log)\n",
    "x_test94 = network.model_to_tanhs(x_test_log94)\n",
    "# x_test2 = network.model_to_tanhs(x_test2_log)\n",
    "# print(x_train)\n",
    "# print(np.max(x_train))\n",
    "\n",
    "AuEM_models1 = np.load('Sampled_Conductivity.npy')\n",
    "AuEM_models2 = np.load('Line2_Central_Conductivity.npy')\n",
    "AuEM_models3 = np.load('Line3_Central_Conductivity.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(x_train_raw.shape)\n",
    "print(x_validate_raw.shape)\n",
    "\n",
    "x_train1 = x_train\n",
    "# print(x_train1)\n",
    "x_validate1 = x_validate[0:3000,]\n",
    "x_train_raw1 = x_train_raw\n",
    "x_validate_raw1 = x_validate_raw[0:3000,]\n",
    "# x_test_raw1 = x_test_raw[0:1000,]\n",
    "# print(x_train_raw1)\n",
    "# plt.plot(x_train_raw1[0],np.append(0,depths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# compute stds\n",
    "model_std = np.std(x_train.flatten())\n",
    "#mt_data_file = 'KGS_MT.npy'\n",
    "#os.remove(mt_data_file)\n",
    "#try:\n",
    "#    all_data = tf.convert_to_tensor(np.load(mt_data_file))\n",
    "#except FileNotFoundError:\n",
    "#    all_data = network.predict_tanh(x_train)\n",
    "#    np.save(mt_data_file, all_data.numpy())\n",
    "train_data = x_train1[:,:,0]\n",
    "# print(train_data)\n",
    "# print(\"train data\", train_data.shape)\n",
    "# print('.........')\n",
    "\n",
    "\n",
    "raw_train = np.asarray(x_train_raw1.T)\n",
    "print(np.shape(raw_train[:,0]))\n",
    "print(times)\n",
    "raw_train_T = raw_train*1e-15\n",
    "raw_train_data = np.gradient(raw_train_T,times, axis=0)\n",
    "raw_train_data = -np.abs(raw_train_data).T\n",
    "# log_train_data = tf.math.log(-train_data)\n",
    "#print('log_train_data'log_train_data.shape)\n",
    "print(\"raw_train_data\", raw_train_data.shape)\n",
    "print(raw_train_data[0])\n",
    "raw_validate = np.asarray(x_validate_raw1.T)\n",
    "raw_validate_T = raw_validate*1e-15\n",
    "raw_validate_data = np.gradient(raw_validate_T,times, axis=0)\n",
    "raw_validate_data = -np.abs(raw_validate_data).T\n",
    "validate_data = x_validate1[:,:,0]\n",
    "# raw_validate_data = -x_validate_raw1\n",
    "\n",
    "raw_test = np.asarray(x_test_raw.T)\n",
    "raw_test_T = raw_test*1e-15\n",
    "print(raw_test_T.shape)\n",
    "raw_test_data = np.gradient(raw_test_T,times, axis=0)\n",
    "raw_test_data = -np.abs(raw_test_data).T\n",
    "\n",
    "raw_test94 = np.asarray(x_test_raw94.T)\n",
    "raw_test94_T = raw_test94*1e-15\n",
    "print(raw_test94_T.shape)\n",
    "raw_test_data94 = np.gradient(raw_test94_T,times, axis=0)\n",
    "raw_test_data94 = -np.abs(raw_test_data94).T\n",
    "\n",
    "# print(raw_validate_data)\n",
    "# test1_data = network.predict_tanh(x_test1)\n",
    "# log_test1_data = tf.math.log(-test1_data)\n",
    "\n",
    "# test2_data = network.predict_tanh(x_test2)\n",
    "# log_test2_data = tf.math.log(-test2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# plt.plot(train_data[0],np.append(0,depths))\n",
    "# plt.plot(obs1_new[0], np.append(0,depths), color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# np.save('train_data.npy',train_data)\n",
    "# np.save('raw_train_data.npy',raw_train_data)\n",
    "# np.save('validate_data.npy',validate_data)\n",
    "# np.save('raw_validate_data.npy',raw_validate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# train_data = np.load('train_data.npy')\n",
    "# raw_train_data = np.load('raw_train_data.npy')\n",
    "# validate_data = np.load('validate_data.npy')\n",
    "# raw_validate_data = np.load('raw_validate_data.npy')\n",
    "print(train_data.shape)\n",
    "print(raw_train_data.shape)\n",
    "\n",
    "# plt.plot(x_train1[0],np.append(0,depths))\n",
    "# plt.plot(train_data[0],np.append(0,depths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # Create batches and shuffle\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "#x_train1 = models *log transform models*; log_train_data: raw data\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    tf.cast(train_data, tf.float32), \n",
    "    tf.cast(raw_train_data, tf.float32))).shuffle(10000).batch(BATCH_SIZE)\n",
    "\n",
    "validate_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    tf.cast(validate_data, tf.float32),\n",
    "    tf.cast(raw_validate_data, tf.float32))).shuffle(10000).batch(x_validate1.shape[0])\n",
    "\n",
    "# though the data vary over several orders of magnitude, \n",
    "# they don't vary so much within one frequency.\n",
    "# data_std_vec = np.std(train_data.numpy(), axis=0)\n",
    "# log_data_std_vec = np.std(log_train_data.numpy(), axis=0)\n",
    "# log_data_std = np.std(log_train_data.numpy().flatten())\n",
    "# average_log_data_std = np.std((log_train_data.numpy() - log_train_data.numpy().mean(axis=0)).flatten())\n",
    "# print(model_std, log_data_std, average_log_data_std)\n",
    "# compute elementwise stds\n",
    "model_std_vec = np.std(x_train1, axis=0)\n",
    "model_std_vec = np.reshape(model_std_vec, (n_cells))\n",
    "# # compute relative std\n",
    "mean_train_data = np.mean(train_data, axis=0)\n",
    "rel_data_std = np.abs(mean_train_data)\n",
    "\n",
    "# same for model, but mean over all\n",
    "mean_model_value = np.mean(x_train1)\n",
    "rel_model_std = 0.5*mean_model_value\n",
    "# print(mean_model_value, rel_model_std)\n",
    "print('data_std',rel_data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# plt.plot(train_dataset[0],np.append(0,depths))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "for i_freq in range(0,nf):\n",
    "    plt.hist(log_train_data.numpy()[:,i_freq].flatten(), bins=50)\n",
    "plt.show()\n",
    "\n",
    "plt.semilogx(frequencies, log_data_std_vec[:nf])\n",
    "plt.semilogx(frequencies, log_data_std_vec[nf:])\n",
    "plt.legend(['real', 'imaginary'])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(model_std_vec)\n",
    "plt.show()\n",
    "\n",
    "plt.loglog(frequencies, data_std_vec[:nf])\n",
    "plt.loglog(frequencies, data_std_vec[nf:])\n",
    "plt.legend(['real', 'imaginary'])\n",
    "plt.show()\n",
    "\n",
    "plt.loglog(frequencies, -np.mean(train_data.numpy(), axis=0)[:nf])\n",
    "plt.loglog(frequencies, -np.mean(train_data.numpy(), axis=0)[nf:])\n",
    "plt.legend(['real', 'imaginary'])\n",
    "plt.show()\n",
    "\n",
    "plt.loglog(frequencies, rel_data_std[:nf])\n",
    "plt.loglog(frequencies, rel_data_std[nf:])\n",
    "plt.legend(['real', 'imaginary'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# finalize network\n",
    "network = vae.CVAE(depths,\n",
    "                   min_model=min_model,\n",
    "                   max_model=max_model,\n",
    "                   times=times,\n",
    "                   norm_pad=norm_pad,\n",
    "                   data_std=rel_data_std.reshape(1, -1, 1),\n",
    "#                    model_std=model_std,\n",
    "                   model_std=model_std_vec.reshape(1, -1, 1),\n",
    "                   latent_dim=20,\n",
    "                   beta_vae=0.01,\n",
    "                   model_loss_type='mae',\n",
    "                   data_loss_type='mae'\n",
    "                  )\n",
    "\n",
    "# double check forward model\n",
    "'''\n",
    "\n",
    "all_data[0, 0], all_data[0, 24]\n",
    "\n",
    "network.predict_tanh(x_train[0:1])\n",
    "\n",
    "c60 = np.load('KSG_RILD_60ft.npy')\n",
    "c60[0].shape\n",
    "\n",
    "vae.forward_1_freq(c60[200], depths, frequencies[0])[0]\n",
    "\n",
    "vae.forward_1_freq(c60[200], depths, frequencies[-1])[0]\n",
    "\n",
    "all_data.numpy().max(), all_data.numpy().min()\n",
    "\n",
    "all_data.shape\n",
    "\n",
    "'''\n",
    "\n",
    "#for i_freq in range(nf):\n",
    "#    plt.hist(all_data.numpy()[:, i_freq].flatten(), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# May be able to remove/adjust steps since I have data instead of models\n",
    "i_random_train = np.arange(16)\n",
    "# random_train = x_train[i_random_train].reshape((16, n_cells))\n",
    "# pick some random training models\n",
    "# i_random_train = np.random.randint(0, x_train1.shape[0], 16)\n",
    "#i_random_train = np.arange(16)\n",
    "random_train = x_train1[i_random_train].reshape((16, 32))\n",
    "# print('i_random_train',i_random_train)\n",
    "# print('random_train',random_train)\n",
    "print(network.predict_tanh(random_train))\n",
    "# predict their data\n",
    "# print(n_cells)\n",
    "random_data = network.predict_tanh(random_train.reshape(16, 32, 1))\n",
    "# print('n_cells',n_cells)\n",
    "random_log_data = tf.math.log(-random_data)\n",
    "# print('random_log_data', random_log_data)\n",
    "print('random_data',random_data)\n",
    "# Save data and latent space inputs for plots\n",
    "# print(network.latent_dim)\n",
    "latent_input = tf.random.normal([16, network.latent_dim], seed=0, dtype=tf.float32)\n",
    "print('latent_input',latent_input)\n",
    "# print('n_data',network.n_data)\n",
    "random_data1 = random_data[:,:16]\n",
    "data_input = tf.reshape(random_data1,(16,network.n_time))\n",
    "print('data_input',data_input)\n",
    "zd_input = tf.concat((latent_input,data_input),axis=-1)\n",
    "print('zd_input',zd_input)\n",
    "# Why are there nan values????? The forward modelling produces (16,30) arrays which should fit perfectly into data_input\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# plot a few random training models and their data\n",
    "# vae.plot_complex(random_data, times=times, save2file=True, filename=run+'/training_MT_data.png')\n",
    "vae.plot_logs(np.exp(network.tanhs_to_model(random_train)), depths=depths, save2file=True, \n",
    "              filename=run + '/training_models.png')\n",
    "\n",
    "# Save starting plots\n",
    "network.plot_models(save2file=True,folder=run,samples=zd_input.shape[0],\n",
    "                    latent=zd_input,step=0)\n",
    "# network.plot_data(save2file=True,folder=run,latent=zd_input,step=0)\n",
    "# network.plot_residuals(save2file=True,folder=run,latent=zd_input,step=0)\n",
    "\n",
    "plt.close('all')\n",
    "plt.clf()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.003, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "k,mlloss = tf.keras.metrics.Mean()\n",
    "loss_terms = []\n",
    "for epoch in range(1, 50 + 1):\n",
    "    start_time = time.time()\n",
    "    for train_x in train_dataset:\n",
    "        l,t = vae.compute_apply_gradients(network, train_x, optimizer, \n",
    "                                          use_data_misfit=True)\n",
    "    end_time = time.time()\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: {}, Elapsed {:.4} s'.format(epoch, end_time-start_time))\n",
    "\n",
    "# compute  losses\n",
    "epoch = 0\n",
    "for epoch in range(50):\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    for train_x in train_dataset:#.batch(BATCH_SIZE):\n",
    "        losses = vae.compute_losses(network, test_x)\n",
    "        terms = [loss(l).numpy() for l in losses]\n",
    "        #loss(vae.compute_reconstruction_loss(network, test_x))\n",
    "    #elbo = -loss.result()\n",
    "    print('Epoch: {}, Data misfit: {:.4}, '\n",
    "          'Reconstruction: {:.4}, '\n",
    "          'KL: {:.4}, '.format(epoch, terms[0], terms[1], terms[2]))\n",
    "\n",
    "from tensorflow.keras.losses import Reduction, MeanSquaredError, MeanAbsoluteError\n",
    "mean_error = MeanSquaredError(reduction=Reduction.NONE)\n",
    "\n",
    "#data_std_vec.shape\n",
    "\n",
    "for test_x in test_dataset:\n",
    "    dpre = network.predict_tanh(test_x[0])\n",
    "    dobs = -tf.exp(test_x[1])\n",
    "    print(tf.sort(mean_error(dpre,dobs,\n",
    "                             sample_weight=data_std_vec[None, :, None]\n",
    "                            )))\n",
    "    #print(dpre)\n",
    "\n",
    "z_model = network.reparameterize(*network.encode(x_test[0:16]))\n",
    "z_data = log_data_test[0:16]\n",
    "zmd = tf.concat((z_model,z_data),-1)\n",
    "network.plot_models(latent=zmd)\n",
    "\n",
    "for _ in range(100):\n",
    "    for test_x in test_dataset:\n",
    "        tcl, tl = vae.compute_loss(network, test_x)\n",
    "        #print('hi')\n",
    "        #print(test_x[0][0,0,0].numpy())\n",
    "        #print(np.mean(test_x[0].numpy().flatten()))\n",
    "        #print(np.mean(test_x[1].numpy().flatten()))\n",
    "        #print([tf.reduce_mean(t).numpy() for t in tcl])\n",
    "        [print(t.numpy()) for t in tl]\n",
    "\n",
    "tcl = vae.compute_losses(network, test_x)\n",
    "print([tf.reduce_mean(t).numpy() for t in tcl])\n",
    "\n",
    "for _ in range(100):\n",
    "    for test_x in test_dataset:\n",
    "        tcl = vae.compute_losses(network, test_x)\n",
    "        #print('hi')\n",
    "    #print(test_x[0][0,0,0].numpy())\n",
    "    #print(np.mean(test_x[0].numpy().flatten()))\n",
    "    #print(np.mean(test_x[1].numpy().flatten()))\n",
    "    print([tf.reduce_mean(t).numpy() for t in tcl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "validate_terms = []\n",
    "train_terms = []\n",
    "train_losses = []\n",
    "ttest_losses = []\n",
    "# print(len(train_dataset))\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "#     print(train_dataset)\n",
    "#     print(optimizer)\n",
    "    for train_x in train_dataset:#.batch(BATCH_SIZE):\n",
    "        # print(train_x)\n",
    "        train_loss, train_term = vae.compute_apply_gradients(network, train_x, optimizer, \n",
    "                                    use_data_misfit=True)\n",
    "        #train_losses.append(train_loss.numpy())\n",
    "        train_terms.append([tt.numpy() for tt in train_term])\n",
    "#         for test_x in test_dataset:\n",
    "#             ttest_loss = vae.compute_losses(network, test_x)\n",
    "#             terms = [loss(l).numpy() for l in ttest_loss]\n",
    "#             ttest_losses.append(terms)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # compute and save losses\n",
    "    for val_x in validate_dataset:#.batch(BATCH_SIZE):\n",
    "        val_loss, val_term = vae.compute_loss(network, val_x)\n",
    "        #terms = [tf.reduce_mean(l).numpy() for l in losses]\n",
    "        #loss(vae.compute_reconstruction_loss(network, test_x))\n",
    "    #elbo = -loss.result()\n",
    "    validate_terms.append([tt.numpy() for tt in val_term])\n",
    "    print('Epoch: {}, Data misfit: {:.4}, '\n",
    "          'Reconstruction: {:.4}, '\n",
    "          'KL: {:.4}, '\n",
    "          'Elapsed {:.4} s'.format(epoch, train_term[0], train_term[1], train_term[2],\n",
    "                                #elbo,\n",
    "                                end_time - start_time))\n",
    "        \n",
    "    if epoch % 1e3 == 0:\n",
    "        network.plot_models(save2file=True,folder=run,samples=zd_input.shape[0],\n",
    "                 latent=zd_input,step=epoch)\n",
    "        network.plot_data(save2file=True,folder=run,latent=zd_input,step=epoch)\n",
    "        network.plot_residuals(save2file=True,folder=run,latent=zd_input,step=epoch)\n",
    "        plt.close('all')\n",
    "        gc.collect()\n",
    "\n",
    "network.inference_net.save(run+'/encoder.h5')\n",
    "network.generative_net.save(run+'/decoder.h5')\n",
    "#np.save(run+'/optimizer_weights.npy', optimizer.load_weights())\n",
    "np.save(run+'/losses.npy', np.array(validate_terms))\n",
    "np.save(run+'/train_losses.npy', np.array(train_terms))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.semilogy(np.array(ttest_losses))\n",
    "plt.legend(['Data misfit', 'Reconstruction', 'KL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "network.inference_net = tf.keras.models.load_model(run+'/encoder.h5')\n",
    "network.generative_net = tf.keras.models.load_model(run+'/decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "loss_terms = np.load(run+'/losses.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#optimizer_weights = np.load(run+'/optimizer_weights.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/49503748/save-and-load-model-optimizer-state to train more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tl = np.array(train_losses)\n",
    "\n",
    "plt.semilogy(tl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tt = np.array(train_terms)\n",
    "batches_per_epoch = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "num_batches = tt.shape[0]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.semilogy(np.arange(num_batches)/batches_per_epoch, tt)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Training epoch')\n",
    "plt.title(\"Traning Loss\")\n",
    "plt.legend(['Data Misfit','Reconstruction error', 'KL divergence'])\n",
    "plt.savefig('training_loss_'+run+'_w.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(np.arange(epochs),validate_terms)\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Training epoch')\n",
    "plt.title('Validation Loss')\n",
    "plt.legend(['Data misfit', 'Reconstruction error', 'KL divergence'])\n",
    "plt.savefig('validation_loss_'+run+'_w.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# print(network.data_weights, network.model_weights, network.beta_vae)\n",
    "weighted_loss_terms = np.array(loss_terms)\n",
    "# weighted_loss_terms *= np.array([network.data_weights, network.model_weights, 1])\n",
    "weighted_loss_terms *= np.array([network.data_weights, network.model_weights, network.beta_vae])\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(np.arange(epochs),weighted_loss_terms)\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Training epoch')\n",
    "plt.legend(['Data misfit', 'Reconstruction error', 'KL divergence'])\n",
    "#plt.savefig('weighted_training_loss_'+run+'_w.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "vae.plot_logs(np.exp(network.tanhs_to_model(x_validate[0:16])), depths=depths, step=16, save2file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "z_model = network.reparameterize(*network.encode(x_validate[0:16]))\n",
    "z_data = raw_validate_data[0:16]\n",
    "zmd = tf.concat((z_model,z_data),-1)\n",
    "network.plot_models(latent=zmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "depth_centers = (network.depths[1:] + network.depths[:-1])/2\n",
    "plot_depths = np.r_[\n",
    "    depth_centers[0] - (depth_centers[1] - depth_centers[0]),\n",
    "    depth_centers,\n",
    "    depth_centers[-1] + depth_centers[-1] - depth_centers[-2]\n",
    "]\n",
    "\n",
    "zmd_tanhs = network.decode(zmd, apply_tanh=True)\n",
    "zmd_samples = zmd_tanhs.shape[0]\n",
    "zmd_tanhs = np.reshape(zmd_tanhs, (zmd_samples, network.n_model))\n",
    "zmd_logs = network.tanhs_to_model(zmd_tanhs)\n",
    "# zmdlogs = np.exp(zmd_logs)\n",
    "\n",
    "true_validate = network.tanhs_to_model(x_validate[0:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Why does x2 on the predicted make it match better???\n",
    "# fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "# for i in range(16):\n",
    "#     plt.subplot(4, 4, i + 1)\n",
    "#     plt.plot(true_validate[i], plot_depths, drawstyle='steps-post', label='True')\n",
    "#     plt.plot(zmd_logs[i][:-2], plot_depths[:-2], drawstyle='steps-post', label='Pred', linestyle='--')\n",
    "#     # plt.xlabel('Conductivity (S/m)')\n",
    "#     # plt.ylabel('Depth (m)')\n",
    "#     plt.suptitle('True vs Predicted Conductivity Plots',fontsize = 30)\n",
    "#     plt.xscale('log')\n",
    "#     plt.gca().invert_yaxis()\n",
    "#     if i == 0:\n",
    "#         plt.legend()\n",
    "\n",
    "# fig.text(0.5, 0.06, 'Conductivity (S/m)', ha='center', va='center', size=20)\n",
    "# fig.text(0.03, 0.5, 'Depth (m)', ha='center', va='center',\n",
    "#              rotation='vertical', size=20)\n",
    "# fig.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "# samples = data.shape[0]\n",
    "subplot_rows = 4\n",
    "subplot_cols = 4\n",
    "for i in range(16):\n",
    "        ax = plt.subplot(subplot_rows, subplot_cols, i+1)\n",
    "        ax.set_title('Sounding %d' %int(i+1), fontsize = 16)\n",
    "        ax.semilogx(np.exp(true_validate[i]), plot_depths, drawstyle='steps-post', label='True')\n",
    "        ax.semilogx(np.exp(zmd_logs[i][:-2]), plot_depths[:-2], drawstyle='steps-post', label='Pred', linestyle='--')\n",
    "        plt.gca().invert_yaxis()\n",
    "plt.legend(bbox_to_anchor=(1.02, 0.1), loc='upper left', borderaxespad=0)\n",
    "fig.text(0.5, 0.06, 'Conductivity (S/m)', ha='center', va='center', size=20)\n",
    "fig.text(0.03, 0.5, 'Depth (m)', ha='center', va='center',\n",
    "             rotation='vertical', size=20)\n",
    "plt.suptitle('True vs Predicted Conductivity Plots',fontsize = 30)\n",
    "plt.tight_layout(rect=(0.05,0.08,1,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def minmax(x): return tf.reduce_min(x), tf.reduce_max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mean_true1 = np.mean(true_validate,axis=0)\n",
    "mean_pred1 = np.mean(zmd_logs,axis=0)\n",
    "\n",
    "mae1_log = mean_absolute_error(mean_true1,mean_pred1)\n",
    "mse1_log = mean_squared_error(mean_true1, mean_pred1)\n",
    "\n",
    "mean_true1_lin = np.exp(mean_true1)\n",
    "mean_pred1_lin = np.exp(mean_pred1)\n",
    "\n",
    "mae1_linear = mean_absolute_error(mean_true1_lin,mean_pred1_lin)\n",
    "mse1_linear = mean_squared_error(mean_true1_lin, mean_pred1_lin)\n",
    "\n",
    "mult_fact1 = np.exp(mae1_log)\n",
    "percent_error1 = (mult_fact1-1)*100\n",
    "\n",
    "print(mae1_log, mse1_log)\n",
    "print(mae1_linear, mse1_linear)\n",
    "print(mult_fact1, percent_error1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tanhs = network.decode(zmd, apply_tanh=True)\n",
    "minmax(tanhs)\n",
    "print(tanhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "minmax(x_test[0:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(zmd.shape)\n",
    "network.plot_data(latent=zmd)\n",
    "\n",
    "# d_obs is from validation seta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "network.plot_residuals(latent=zmd, weighted=False, step=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomize latent; does data still fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "vae.plot_logs(np.exp(network.tanhs_to_model(x_test[0   :16])), depths=depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(x_test[0:1,:,0].shape)\n",
    "print(z_data[0:1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data0 = tf.tile(z_data[0:1],[16,1])\n",
    "# print(latent_input)\n",
    "data0 = tf.cast(data0, tf.float32)\n",
    "# print(data0)\n",
    "zmd2 = tf.concat((latent_input,data0),-1)\n",
    "# print(zmd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "network.plot_models(latent=zmd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "zmd2_tanhs = network.decode(zmd2, apply_tanh=True)\n",
    "zmd2_samples = zmd2_tanhs.shape[0]\n",
    "zmd2_tanhs = np.reshape(zmd2_tanhs, (zmd2_samples, network.n_model))\n",
    "zmd2_logs = network.tanhs_to_model(zmd2_tanhs)\n",
    "# zmd2 = (10**zmd2_logs)-1\n",
    "\n",
    "\n",
    "true_test = tf.tile(x_test[0:1,:,0],[16,1])\n",
    "true_test = tf.cast(true_test, tf.float32)\n",
    "true_test1 = network.tanhs_to_model(true_test)\n",
    "# true_test1 = (10**true_test1)-1\n",
    "print(true_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "zmd2_logs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# plt.figure(figsize=(20, 20))\n",
    "\n",
    "# for i in range(16):\n",
    "#     plt.subplot(4, 4, i + 1)\n",
    "#     plt.plot(true_test1[i], plot_depths, drawstyle='steps-post', label='True')\n",
    "#     plt.plot(np.exp(zmd2_logs[i][:-2]), plot_depths[:-2], drawstyle='steps-post', label='Pred', linestyle='--')\n",
    "#     plt.xscale('log')\n",
    "#     # plt.plot(zmd2_logs[i], plot_depths, label='Pred_logs', linestyle='--')\n",
    "#     plt.gca().invert_yaxis()\n",
    "#     if i == 0:\n",
    "#         plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "# samples = data.shape[0]\n",
    "subplot_rows = 4\n",
    "subplot_cols = 4\n",
    "for i in range(16):\n",
    "        ax = plt.subplot(subplot_rows, subplot_cols, i+1)\n",
    "        ax.set_title('Sounding %d' %int(i+1), fontsize = 16)\n",
    "        ax.semilogx(np.exp(true_test1[i]), plot_depths, drawstyle='steps-post', label='True')\n",
    "        ax.semilogx(np.exp(zmd2_logs[i][:-2]), plot_depths[:-2], drawstyle='steps-post', label='Pred', linestyle='--')\n",
    "        plt.gca().invert_yaxis()\n",
    "plt.legend(bbox_to_anchor=(1.02, 0.1), loc='upper left', borderaxespad=0)\n",
    "fig.text(0.5, 0.06, 'Conductivity (S/m)', ha='center', va='center', size=20)\n",
    "fig.text(0.03, 0.5, 'Depth (m)', ha='center', va='center',\n",
    "             rotation='vertical', size=20)\n",
    "plt.suptitle('True vs Predicted Conductivity Plots',fontsize = 30)\n",
    "plt.tight_layout(rect=(0.05,0.08,1,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "mean_cond2 = np.mean(zmd2_logs,axis=0)\n",
    "mean_true_cond2 = np.mean(true_test1, axis=0)\n",
    "std_cond = np.std(zmd2_logs,axis=0)\n",
    "print(std_cond)\n",
    "print(mean_cond2)\n",
    "mae2_log = mean_absolute_error(mean_true_cond2,mean_cond2)\n",
    "mse2_log = mean_squared_error(mean_true_cond2, mean_cond2)\n",
    "\n",
    "mean_true2_lin = np.exp(mean_true_cond2)\n",
    "mean_pred2_lin = np.exp(mean_cond2)\n",
    "\n",
    "mae2_linear = mean_absolute_error(mean_true2_lin,mean_pred2_lin)\n",
    "mse2_linear = mean_squared_error(mean_true2_lin, mean_pred2_lin)\n",
    "\n",
    "mult_fact2 = np.exp(mae2_log)\n",
    "percent_error2 = (mult_fact2-1)*100\n",
    "\n",
    "print(mae2_log, mse2_log)\n",
    "print(mae2_linear, mse2_linear)\n",
    "print(mult_fact2, percent_error2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for log in zmd2_logs:\n",
    "    ax.plot(np.exp(log[:-2]), plot_depths[:-2],drawstyle='steps-post', c='k', alpha=0.2)\n",
    "ax.plot(np.exp(mean_cond2[:-2]), plot_depths[:-2], drawstyle='steps-post',label='Mean')\n",
    "ax.plot(np.exp(mean_cond2[:-2]+std_cond[:-2]),plot_depths[:-2], drawstyle='steps-post', c='m', label=\"One Std\")\n",
    "ax.plot(np.exp(mean_cond2[:-2]-std_cond[:-2]), plot_depths[:-2], drawstyle='steps-post', c='m')\n",
    "ax.plot(np.exp(mean_cond2[:-2]+2*std_cond[:-2]), plot_depths[:-2], drawstyle='steps-post', c='g', label= 'Two Std') # type: ignore\n",
    "ax.plot(np.exp(mean_cond2[:-2]-2*std_cond[:-2]), plot_depths[:-2], drawstyle='steps-post', c='g')\n",
    "# ax.plot(true_test1[1],plot_depths, c='orange', label = 'True Mean')\n",
    "ax.invert_yaxis()\n",
    "ax.axes.set_xlabel(\"Conductivity (S/m)\")\n",
    "ax.axes.set_ylabel(\"Depth (m)\")\n",
    "ax.axes.set_xscale('log')\n",
    "# ax.axes.set_xlim(1e-1, 1e3)\n",
    "ax.axes.set_title('(A)')\n",
    "ax.axes.legend(fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Preliminary_generated_plots_mean&2std.jpg')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for log in zmd2_logs:\n",
    "    ax.semilogx(np.exp(log)[:-2], plot_depths[:-2],drawstyle='steps-post', c='k', alpha=0.2)\n",
    "ax.semilogx(np.exp(mean_cond2)[:-2], plot_depths[:-2],drawstyle='steps-post',label='Mean')\n",
    "ax.semilogx(np.exp(mean_cond2+std_cond**2)[:-2], plot_depths[:-2], drawstyle='steps-post', c='orange', label='Variance')\n",
    "ax.semilogx(np.exp(mean_cond2-std_cond**2)[:-2], plot_depths[:-2], drawstyle='steps-post', c='orange')\n",
    "ax.invert_yaxis()\n",
    "ax.axes.set_xlabel(\"Conductivity (S/m)\")\n",
    "ax.axes.set_ylabel(\"Depth (m)\")\n",
    "# ax.axes.set_xlim(1e-4, 1e5)\n",
    "ax.axes.set_title('(B)')\n",
    "ax.axes.legend(fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Preliminary_generated_plots.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # Example inputs\n",
    "# conductivities = [0.01, 0.1, 0.05, 0.2, 0.01]  # Conductivity (S/m) for each layer\n",
    "# thicknesses = [10, 20, 20, 30, 20]  # Thickness of each layer (m)\n",
    "\n",
    "# # Compute depths from thicknesses\n",
    "# depths = np.cumsum(thicknesses)  # Compute layer boundaries\n",
    "# depths = np.insert(depths, 0, 0)  # Insert surface depth at 0\n",
    "\n",
    "# # Create step-like depth and conductivity arrays\n",
    "# depth_plot = np.repeat(plot_depths, 2)  # Duplicate depths for step changes\n",
    "# conductivity_plot = np.repeat(zmd2_logs[0], 2)  # Duplicate conductivity values\n",
    "\n",
    "depth_plot = np.repeat(plot_depths, 2)\n",
    "# depth_plot=np.flip(depth_plot)\n",
    "\n",
    "fig, ax = plt.subplots(1,4,figsize=(20, 10))\n",
    "\n",
    "# plt.ticklabel_format(axis='y', style='sci', scilimits=(4, 4))\n",
    "# fig.suptitle('VAE Generated Models')\n",
    "for log in zmd2:\n",
    "    conductivity_plot = np.repeat(log,2)\n",
    "    # ax[0].semilogx(conductivity_plot, depth_plot, drawstyle='steps-post', color='k', alpha=0.2)\n",
    "\n",
    "# for i in AuEM_models3[0:1000,]:\n",
    "    # ax[1].semilogx(i, plot_depths, drawstyle='steps-post', color='k', alpha=0.2)\n",
    "\n",
    "mean_cond_plot = np.repeat(mean_cond2,2)\n",
    "mean_true_cond_plot = np.repeat(mean_true_cond2,2)\n",
    "\n",
    "difference = np.abs(np.exp(mean_true_cond2) + np.exp(mean_cond2))\n",
    "print(np.mean(difference))\n",
    "print(np.exp(mean_cond2))\n",
    "print(mean_true_cond2)\n",
    "\n",
    "ax[0].semilogx(np.exp(mean_cond2[:-2]),plot_depths[:-2], drawstyle='steps-post', c='b', label='Mean')\n",
    "ax[0].invert_yaxis()\n",
    "ax[0].set_xlabel('Conductivity (S/m)')\n",
    "ax[0].set_ylabel('Depth (m)')\n",
    "ax[0].set_title('Generated', fontsize=20)\n",
    "\n",
    "ax[1].semilogx(np.exp(mean_true_cond2), plot_depths, drawstyle='steps-post', c='b', label='Mean')\n",
    "ax[1].invert_yaxis()\n",
    "ax[1].set_xlabel('Conductivity (S/m)')\n",
    "ax[1].set_ylabel('Depth (m)')\n",
    "ax[1].set_title('True', fontsize=20)\n",
    "\n",
    "ax[2].semilogx(difference[:-2], plot_depths[:-2], drawstyle='steps-post', c='b')\n",
    "ax[2].invert_yaxis()\n",
    "ax[2].set_xlabel('Conductivity (S/m)')\n",
    "ax[2].set_ylabel('Depth (m)')\n",
    "ax[2].set_title('Difference', fontsize=20)\n",
    "\n",
    "ax[3].semilogx(np.exp(mean_cond2[:-2]),plot_depths[:-2], drawstyle='steps-post', c='b', label='Pred')\n",
    "ax[3].semilogx(np.exp(mean_true_cond2), plot_depths, drawstyle='steps-post', c='r', label='True')\n",
    "ax[3].invert_yaxis()\n",
    "ax[3].legend()\n",
    "ax[3].set_xlabel('Conductivity (S/m)')\n",
    "ax[3].set_ylabel('Depth (m)')\n",
    "ax[3].set_title('Compared', fontsize=20)\n",
    "# plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('Comparison_GeneratedvsTrue.jpg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "-tf.exp(zmd2[0, 50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "network.plot_data(latent=zmd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "network.plot_residuals(latent=zmd2, weighted=True, step=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "y_true = [[0., 0.], \n",
    "          [0., 0.]]\n",
    "y_pred = [[3., 0.], \n",
    "          [2., 0.]]\n",
    "# Using 'auto'/'sum_over_batch_size' reduction type.\n",
    "# Using 'none' reduction type.\n",
    "mse = tf.keras.losses.MeanSquaredError(\n",
    "    reduction=tf.keras.losses.Reduction.NONE)\n",
    "# Calling with 'sample_weight'.\n",
    "mse(y_true, y_pred, sample_weight=[0.7, 0.3]).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "1/2*((3-0)**2 + 0**2)*.7, 1/2*((2-0)**2 + (0-0)**2)*.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "network.data_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample latent & different data soundings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Plot true models for comparisons - need models for line 94 and adjust plot_logs to show true models too\n",
    "\n",
    "data_batch = raw_test_data94[0:16]\n",
    "latent_dim = 20  # known from model\n",
    "latent_input = tf.random.normal((16, latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "zmd3 = tf.concat(((latent_input), data_batch), -1)\n",
    "print(zmd3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "zmd3_tanhs = network.decode(zmd3, apply_tanh=True)\n",
    "zmd3_samples = zmd3_tanhs.shape[0]\n",
    "zmd3_tanhs = np.reshape(zmd3_tanhs, (zmd3_samples, network.n_model))\n",
    "zmd3_logs = network.tanhs_to_model(zmd3_tanhs)\n",
    "# zmd3_exp = (10**zmd3_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "true_models = x_test94[0:2000]\n",
    "true_logs = network.tanhs_to_model(true_models)\n",
    "true_models = np.exp(true_logs)\n",
    "print(true_logs[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "vae.plot_logs(true_models[0:16], depths=depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "network.plot_models(latent=zmd3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# plt.figure(figsize=(20, 20))\n",
    "\n",
    "# for i in range(16):\n",
    "#     plt.subplot(4, 4, i + 1)\n",
    "#     plt.plot(true_logs[i][:-2], plot_depths[:-2], drawstyle='steps-post', label='True')\n",
    "#     plt.plot(np.exp(zmd3_logs[i])[:-2], plot_depths[:-2], drawstyle='steps-post', label='Pred', linestyle='--')\n",
    "#     plt.xscale('log')\n",
    "#     plt.gca().invert_yaxis()\n",
    "#     if i == 0:\n",
    "#         plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "# samples = data.shape[0]\n",
    "subplot_rows = 4\n",
    "subplot_cols = 4\n",
    "for i in range(16):\n",
    "        ax = plt.subplot(subplot_rows, subplot_cols, i+1)\n",
    "        ax.set_title('Sounding %d' %int(i+1), fontsize = 16)\n",
    "        ax.semilogx(np.exp(true_logs[i]), plot_depths, drawstyle='steps-post', label='True')\n",
    "        ax.semilogx(np.exp(zmd3_logs[i][:-2]), plot_depths[:-2], drawstyle='steps-post', label='Pred', linestyle='--')\n",
    "        plt.gca().invert_yaxis()\n",
    "plt.legend(bbox_to_anchor=(1.02, 0.1), loc='upper left', borderaxespad=0)\n",
    "fig.text(0.5, 0.06, 'Conductivity (S/m)', ha='center', va='center', size=20)\n",
    "fig.text(0.03, 0.5, 'Depth (m)', ha='center', va='center',\n",
    "             rotation='vertical', size=20)\n",
    "plt.suptitle('True vs Predicted Conductivity Plots',fontsize = 30)\n",
    "plt.tight_layout(rect=(0.05,0.08,1,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "network.plot_data(latent=zmd3)\n",
    "# Why only one sounding???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# zmd3_tanhs = network.decode(zmd3, apply_tanh=True)\n",
    "# zmd3_samples = zmd3_tanhs.shape[0]\n",
    "# zmd3_tanhs = np.reshape(zmd3_tanhs, (zmd3_samples, network.n_model))\n",
    "# zmd3_logs = np.exp(network.tanhs_to_model(zmd3_tanhs))\n",
    "# zmd3_exp = (10**zmd3_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "network.plot_residuals(latent=zmd3, step=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# plt.figure(figsize=(20, 20))\n",
    "\n",
    "array1 = np.array(range(0,1600,100))\n",
    "# print(array1)\n",
    "\n",
    "# print(true_logs.shape)\n",
    "# for i in range(len(array1)):\n",
    "#     j = array1[i]\n",
    "#     plt.subplot(4, 4,  i+1)\n",
    "#     plt.plot(true_logs[j][:-2], plot_depths[:-2], drawstyle='steps-post')\n",
    "#     plt.xscale('log')\n",
    "#     plt.gca().invert_yaxis()\n",
    "#     # if i == 0:\n",
    "#     #     plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "# samples = data.shape[0]\n",
    "subplot_rows = 4\n",
    "subplot_cols = 4\n",
    "for i in range(len(array1)):\n",
    "        j = array1[i]\n",
    "        ax = plt.subplot(subplot_rows, subplot_cols, i+1)\n",
    "        ax.set_title('Sounding %d' %int(i+1), fontsize = 16)\n",
    "        ax.semilogx(np.exp(true_logs[j][:-2]), plot_depths[:-2], drawstyle='steps-post', label='True')\n",
    "        plt.gca().invert_yaxis()\n",
    "# plt.legend(bbox_to_anchor=(1.02, 0.1), loc='upper left', borderaxespad=0)\n",
    "fig.text(0.5, 0.06, 'Conductivity (S/m)', ha='center', va='center', size=20)\n",
    "fig.text(0.03, 0.5, 'Depth (m)', ha='center', va='center',\n",
    "             rotation='vertical', size=20)\n",
    "plt.suptitle('Conductivity Plots',fontsize = 30)\n",
    "plt.tight_layout(rect=(0.05,0.08,1,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "mean_true3 = np.mean(true_logs,axis=0)\n",
    "mean_pred3 = np.mean(zmd3_logs,axis=0)\n",
    "\n",
    "mae3_log = mean_absolute_error(mean_true3,mean_pred3)\n",
    "mse3_log = mean_squared_error(mean_true3, mean_pred3)\n",
    "\n",
    "mean_true3_lin = np.exp(mean_true3)\n",
    "mean_pred3_lin = np.exp(mean_pred3)\n",
    "\n",
    "mae3_linear = mean_absolute_error(mean_true3_lin,mean_pred3_lin)\n",
    "mse3_linear = mean_squared_error(mean_true3_lin, mean_pred3_lin)\n",
    "\n",
    "mult_fact3 = np.exp(mae3_log)\n",
    "percent_error3 = (mult_fact3-1)*100\n",
    "\n",
    "print(mae3_log, mse3_log)\n",
    "print(mae3_linear, mse3_linear)\n",
    "print(mult_fact3, percent_error3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "lower_log = mean_pred3_lin/mult_fact3\n",
    "upper_log = mean_pred3_lin*mult_fact3\n",
    "\n",
    "lower_lin = np.clip(mean_pred3_lin-mae3_linear, a_min=1e-6, a_max=None)\n",
    "upper_lin = mean_pred3_lin+mae3_linear\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "\n",
    "# Left: Linear error bands\n",
    "axes[0].semilogx(mean_true3_lin, plot_depths, 'ko', label=\"Observed\")\n",
    "axes[0].semilogx(mean_pred3_lin[:-2], plot_depths[:-2], 'r-', label=\"Predicted\")\n",
    "axes[0].semilogx(np.log(lower_lin), plot_depths, 'b--', label=\"± Linear MAE\")\n",
    "axes[0].semilogx(np.log(upper_lin), plot_depths, 'b--')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel(\"Conductivity\")\n",
    "axes[0].set_title(\"Additive Error (Linear MAE)\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Right: Log error bands\n",
    "axes[1].semilogx(mean_true3_lin, plot_depths, 'ko', label=\"Observed\")\n",
    "axes[1].semilogx(mean_pred3_lin[:-2], plot_depths[:-2], 'r-', label=\"Predicted\")\n",
    "axes[1].semilogx(lower_log, plot_depths, 'g--', label=\"×/÷ Factor Band\")\n",
    "axes[1].semilogx(upper_log, plot_depths, 'g--')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].set_xlabel(\"Conductivity\")\n",
    "axes[1].set_title(\"Multiplicative Error (Log MAE)\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simpeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
